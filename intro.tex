\chapter{Introduction}
\label{cha:intro}
\section{The need for data integration methods}
Current advancements in technology are leading to increasingly larger datasets\cite{collins2003vision}. This is a trend that is becoming very apparent in many different fields of research. One of these is the biomedical field. By larger datasets we mean that they are increasing both in the number of variables, aswell as in the number of samples that are available. The increase in variable count is mainly due to technology. We are reaching the point where we are able to sequence anyones DNA at a very low cost\cite{shendure2008next}. Keeping in mind that humans have around 20.000-25.000 proteine-coding genes, it is very common for current genome-datasets to have thousands of variables. Another example is that we have a range of highly advanced imaging instruments in almost every hospital\cite{black1993advances}\cite{medicalimaging}. These instruments provide high quality images from which we can extract even more feature variables to analyze. These are just two examples that show the growth of variable count. Next to the explosion of the number of variables, the number of samples that are available in databases grows aswell. This is because we are able to simply store much more data now than we could in the past, and on top of that, there are big efforts going on to make datasets open to the public to help researchers around the world work together\cite{stark2006biogrid}\cite{sandelin2004jaspar}\cite{tcga}\cite{smith2007obo}. All of these trends lead to huge amounts of data from different sources becoming available for analysis. This raises the question of how we have to combine (or integrate) data from these different sources to get the most information out of them.
\section{Goals and modus operandi}
The aim of this thesis is to develop several integration strategies and show that these strategies have an impact on the performance of predictive models. This aim is encompassed by the bigger study that attempts to find patterns in the huge amounts of cancer data that we have available. By building better predictive models, we can find new insights into the way cancer originates and develops and this will eventually lead to better treatments in the future. Note that there are many kinds of predictive models available in machine learning. There are linear models such as generalized linear models and perceptrons, and there are non-linear models such as deep neural networks. In this thesis we wil put our focus on two types of models: logistic regression - and cox proportional hazards models. There is no special motivation for choosing these two types of models other than the fact that the data to compute them was available to us. There are many other model types that we could have chosen, and this should indeed be the topic of future research. The first chapter explains the first type of predictive models which are called generalized linear models. More specifically this thesis will focus on the logistic regression model. The next chapter explains the second type of predictive models which are called survival models. In this case we will take a closer look at cox proportional hazards models. Once we have established the notion of predictive modelling, we can define the different integration strategies. This is done in chapter three. In order to investigate whether these integration strategies have an effect on the performance of the predictive models, we will apply them to a real world example in two case studies, this is the content of chapter four. The first case study will use logistic regression to build predictive models using the various integration strategies. The data that is used in this case consists of imaging data taken for patients with colorectal cancer. This data was obtained from the University Hospital in Leuven in order to improve their predictive models for medical decision support. The second case study will create survival models from datasets that are obtained from The Cancer Genome Atlas (TCGA). TCGA is an online, publicly available, database of 2.5 petabytes of data on cancer patients. These datasets mainly focus on anything related to the genome or molecular processes. In both case studies we will construct predictive models for all datasets individually, aswell as constructing predictive models using the various integration strategies. Once we have constructed all these models we will compare them using appropriate metrics. In the case of logistic regression models we will use ROC analysis to evaluate the models. In the case of the survival models we will use the Wald significance test to perform the evaluation. \\ \\
In order to facilitate all of the previous work we designed an interactive application that streamlines this whole process. The application is capable of comparing the performance of predictive models using the various integration strategies. This allowed us to perform the two case studies, but it also provides a platform for future research. 
%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 
